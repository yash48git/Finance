{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx19MftXY0dnnlXnRPSoYN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yash48git/Finance/blob/main/Pandas_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41LiXEnvM7lm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b44b9b43"
      },
      "source": [
        "### 1. Introduction to Pandas\n",
        "\n",
        "Pandas is a fast, powerful, flexible, and easy-to-use open-source data analysis and manipulation tool, built on top of the Python programming language.\n",
        "\n",
        "Its two primary data structures are:\n",
        "*   **Series**: A one-dimensional labeled array capable of holding any data type.\n",
        "*   **DataFrame**: A two-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or a SQL table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4f6cbe3",
        "outputId": "c0fd9a4b-896e-4b2c-f930-a17acf90bac2"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating a Series\n",
        "s = pd.Series([1, 3, 5, 6, 8])\n",
        "print(\"Series:\\n\", s)\n",
        "\n",
        "# Creating a DataFrame from a dictionary\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [25, 30, 35, 40],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"\\nDataFrame:\\n\", df)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series:\n",
            " 0    1\n",
            "1    3\n",
            "2    5\n",
            "3    6\n",
            "4    8\n",
            "dtype: int64\n",
            "\n",
            "DataFrame:\n",
            "       Name  Age         City\n",
            "0    Alice   25     New York\n",
            "1      Bob   30  Los Angeles\n",
            "2  Charlie   35      Chicago\n",
            "3    David   40      Houston\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72aea5c5"
      },
      "source": [
        "### 2. Loading Data\n",
        "\n",
        "One of the most common tasks is loading data from various sources into a DataFrame. CSV and Excel files are very common."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac0cffa0"
      },
      "source": [
        "# Create a dummy CSV file for demonstration\n",
        "df.to_csv('sample_data.csv', index=False)\n",
        "\n",
        "# Loading a CSV file\n",
        "df_csv = pd.read_csv('sample_data.csv')\n",
        "print(\"\\nLoaded from CSV:\\n\", df_csv)\n",
        "\n",
        "# Loading an Excel file (requires openpyxl installed: pip install openpyxl)\n",
        "# df.to_excel('sample_data.xlsx', index=False)\n",
        "# df_excel = pd.read_excel('sample_data.xlsx')\n",
        "# print(\"\\nLoaded from Excel:\\n\", df_excel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14a42e54"
      },
      "source": [
        "### 3. Viewing and Inspecting Data\n",
        "\n",
        "After loading, you'll want to get a quick overview of your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d36b8bc1"
      },
      "source": [
        "# Display the first 5 rows\n",
        "print(\"\\nHead (first 5 rows):\\n\", df.head())\n",
        "\n",
        "# Display the last 3 rows\n",
        "print(\"\\nTail (last 3 rows):\\n\", df.tail(3))\n",
        "\n",
        "# Get a concise summary of the DataFrame (data types, non-null values)\n",
        "print(\"\\nInfo:\\n\")\n",
        "df.info()\n",
        "\n",
        "# Get descriptive statistics for numerical columns\n",
        "print(\"\\nDescribe (numerical columns):\\n\", df.describe())\n",
        "\n",
        "# Get the shape (rows, columns)\n",
        "print(\"\\nShape (rows, columns):\", df.shape)\n",
        "\n",
        "# Get column names\n",
        "print(\"\\nColumns:\", df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae9c2b20"
      },
      "source": [
        "### 4. Selection and Indexing\n",
        "\n",
        "Accessing specific columns or rows is fundamental."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67011f93"
      },
      "source": [
        "# Select a single column\n",
        "print(\"\\nSingle Column 'Age':\\n\", df['Age'])\n",
        "\n",
        "# Select multiple columns\n",
        "print(\"\\nMultiple Columns 'Name' and 'City':\\n\", df[['Name', 'City']])\n",
        "\n",
        "# Select rows by label using .loc[] (label-based indexing)\n",
        "print(\"\\nRow with label 1 using .loc:\\n\", df.loc[1])\n",
        "\n",
        "# Select a slice of rows by label\n",
        "print(\"\\nRows with labels 0 to 2 using .loc:\\n\", df.loc[0:2])\n",
        "\n",
        "# Select rows and columns by label\n",
        "print(\"\\nRows 0 to 1, Columns 'Name' and 'Age' using .loc:\\n\", df.loc[0:1, ['Name', 'Age']])\n",
        "\n",
        "# Select rows by integer position using .iloc[] (integer-location based indexing)\n",
        "print(\"\\nRow at integer position 2 using .iloc:\\n\", df.iloc[2])\n",
        "\n",
        "# Select a slice of rows by integer position\n",
        "print(\"\\nRows at integer positions 0 to 2 using .iloc:\\n\", df.iloc[0:3])\n",
        "\n",
        "# Select rows and columns by integer position\n",
        "print(\"\\nRows 0 to 1, Columns 0 to 1 using .iloc:\\n\", df.iloc[0:2, 0:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f3b6825"
      },
      "source": [
        "### 5. Filtering Data\n",
        "\n",
        "Filtering allows you to select rows based on specific conditions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5678882a"
      },
      "source": [
        "# Filter rows where 'Age' is greater than 30\n",
        "print(\"\\nPeople older than 30:\\n\", df[df['Age'] > 30])\n",
        "\n",
        "# Filter with multiple conditions (use & for AND, | for OR)\n",
        "print(\"\\nPeople older than 30 AND living in Chicago:\\n\", df[(df['Age'] > 30) & (df['City'] == 'Chicago')])\n",
        "\n",
        "# Filter using .isin()\n",
        "print(\"\\nPeople living in New York or Houston:\\n\", df[df['City'].isin(['New York', 'Houston'])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d670131f"
      },
      "source": [
        "### 6. Handling Missing Values\n",
        "\n",
        "Missing data (NaN) is a common issue. Pandas provides tools to deal with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3f776e4",
        "outputId": "e89630da-6872-454d-fb1c-8aa8c4896385"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_missing = pd.DataFrame({\n",
        "    'A': [1, 2, np.nan, 4],\n",
        "    'B': [5, np.nan, np.nan, 8],\n",
        "    'C': [10, 20, 30, 40]\n",
        "})\n",
        "print(\"\\nDataFrame with missing values:\\n\", df_missing)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values (boolean):\\n\", df_missing.isnull())\n",
        "print(\"\\nMissing values count per column:\\n\", df_missing.isnull().sum())\n",
        "\n",
        "# Drop rows with any missing values\n",
        "print(\"\\nDataFrame after dropping rows with NaN:\\n\", df_missing.dropna())\n",
        "\n",
        "# Fill missing values with a specific value (e.g., 0)\n",
        "print(\"\\nDataFrame after filling NaN with 0:\\n\", df_missing.fillna(0))\n",
        "\n",
        "# Fill missing values with the mean of the column\n",
        "print(\"\\nDataFrame after filling NaN in 'A' with its mean:\\n\", df_missing['A'].fillna(df_missing['A'].mean()))\n",
        "\n",
        "# Forward fill (propagate last valid observation forward to next valid)\n",
        "print(\"\\nDataFrame after forward fill:\\n\", df_missing.fillna(method='ffill'))\n",
        "\n",
        "# Backward fill (propagate next valid observation backward to next valid)\n",
        "print(\"\\nDataFrame after backward fill:\\n\", df_missing.fillna(method='bfill'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with missing values:\n",
            "      A    B   C\n",
            "0  1.0  5.0  10\n",
            "1  2.0  NaN  20\n",
            "2  NaN  NaN  30\n",
            "3  4.0  8.0  40\n",
            "\n",
            "Missing values (boolean):\n",
            "        A      B      C\n",
            "0  False  False  False\n",
            "1  False   True  False\n",
            "2   True   True  False\n",
            "3  False  False  False\n",
            "\n",
            "Missing values count per column:\n",
            " A    1\n",
            "B    2\n",
            "C    0\n",
            "dtype: int64\n",
            "\n",
            "DataFrame after dropping rows with NaN:\n",
            "      A    B   C\n",
            "0  1.0  5.0  10\n",
            "3  4.0  8.0  40\n",
            "\n",
            "DataFrame after filling NaN with 0:\n",
            "      A    B   C\n",
            "0  1.0  5.0  10\n",
            "1  2.0  0.0  20\n",
            "2  0.0  0.0  30\n",
            "3  4.0  8.0  40\n",
            "\n",
            "DataFrame after filling NaN in 'A' with its mean:\n",
            " 0    1.000000\n",
            "1    2.000000\n",
            "2    2.333333\n",
            "3    4.000000\n",
            "Name: A, dtype: float64\n",
            "\n",
            "DataFrame after forward fill:\n",
            "      A    B   C\n",
            "0  1.0  5.0  10\n",
            "1  2.0  5.0  20\n",
            "2  2.0  5.0  30\n",
            "3  4.0  8.0  40\n",
            "\n",
            "DataFrame after backward fill:\n",
            "      A    B   C\n",
            "0  1.0  5.0  10\n",
            "1  2.0  8.0  20\n",
            "2  4.0  8.0  30\n",
            "3  4.0  8.0  40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1329743061.py:24: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  print(\"\\nDataFrame after forward fill:\\n\", df_missing.fillna(method='ffill'))\n",
            "/tmp/ipython-input-1329743061.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  print(\"\\nDataFrame after backward fill:\\n\", df_missing.fillna(method='bfill'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1701954"
      },
      "source": [
        "### 7. Data Manipulation (Groupby, Merge, Apply)\n",
        "\n",
        "These are powerful operations for transforming your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be9f3d9a"
      },
      "source": [
        "data_sales = {\n",
        "    'Product': ['A', 'B', 'A', 'C', 'B', 'A'],\n",
        "    'Region': ['East', 'West', 'East', 'East', 'West', 'Central'],\n",
        "    'Sales': [100, 150, 120, 90, 200, 110]\n",
        "}\n",
        "df_sales = pd.DataFrame(data_sales)\n",
        "print(\"\\nSales DataFrame:\\n\", df_sales)\n",
        "\n",
        "# Group by 'Product' and sum 'Sales'\n",
        "print(\"\\nSales by Product:\\n\", df_sales.groupby('Product')['Sales'].sum())\n",
        "\n",
        "# Group by multiple columns\n",
        "print(\"\\nSales by Product and Region:\\n\", df_sales.groupby(['Product', 'Region'])['Sales'].mean())\n",
        "\n",
        "# Merge two DataFrames (like SQL JOIN)\n",
        "df_customers = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'CustomerID': [1, 2, 3, 4]\n",
        "})\n",
        "df_orders = pd.DataFrame({\n",
        "    'CustomerID': [1, 2, 1, 3],\n",
        "    'OrderAmount': [50, 75, 60, 120]\n",
        "})\n",
        "\n",
        "merged_df = pd.merge(df_customers, df_orders, on='CustomerID', how='inner')\n",
        "print(\"\\nMerged DataFrame (customers and orders):\\n\", merged_df)\n",
        "\n",
        "# Apply a function to a column\n",
        "df['Age_Category'] = df['Age'].apply(lambda x: 'Young' if x < 30 else 'Adult')\n",
        "print(\"\\nDataFrame with new 'Age_Category' column:\\n\", df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b78d141c"
      },
      "source": [
        "### 8. Basic Data Cleaning (Data Type Conversion)\n",
        "\n",
        "Ensuring columns have the correct data type is crucial for analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d4db3d1"
      },
      "source": [
        "df_types = pd.DataFrame({\n",
        "    'A': ['1', '2', '3'],\n",
        "    'B': ['4.5', '5.5', '6.5'],\n",
        "    'C': ['True', 'False', 'True']\n",
        "})\n",
        "print(\"\\nOriginal Data Types:\\n\", df_types.dtypes)\n",
        "\n",
        "# Convert 'A' to integer\n",
        "df_types['A'] = df_types['A'].astype(int)\n",
        "\n",
        "# Convert 'B' to float\n",
        "df_types['B'] = pd.to_numeric(df_types['B'])\n",
        "\n",
        "# Convert 'C' to boolean\n",
        "df_types['C'] = df_types['C'].astype(bool)\n",
        "\n",
        "print(\"\\nNew Data Types after conversion:\\n\", df_types.dtypes)\n",
        "\n",
        "# Convert a string column to datetime (common for date columns)\n",
        "# df_dates = pd.DataFrame({'DateString': ['2023-01-01', '2023-01-02']})\n",
        "# df_dates['Date'] = pd.to_datetime(df_dates['DateString'])\n",
        "# print(\"\\nDates DataFrame with datetime column:\\n\", df_dates.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd25737b"
      },
      "source": [
        "### 9. Saving Data\n",
        "\n",
        "After your analysis or transformations, you'll often want to save your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd7a7449"
      },
      "source": [
        "# Save to CSV\n",
        "df.to_csv('output_data.csv', index=False)\n",
        "print(\"\\nDataFrame saved to 'output_data.csv'\")\n",
        "\n",
        "# Save to Excel\n",
        "# df.to_excel('output_data.xlsx', index=False)\n",
        "# print(\"\\nDataFrame saved to 'output_data.xlsx'\")\n",
        "\n",
        "# You can also save to other formats like JSON, SQL databases, etc."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93f70842"
      },
      "source": [
        "These examples cover a significant portion of what you'll typically do with Pandas. Practice them often, and don't hesitate to refer to the official Pandas documentation for more in-depth information!"
      ]
    }
  ]
}